{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello, everyone. In this notebook, You can create all the dependency file and features to run my NN and LGB model.\n",
    "\n",
    "NOTICE: \n",
    "1. I don't rerun the total approach, expecially i do not make sure filepath is correct. So you may need to check the input file path, but it should be easy.\n",
    "\n",
    "2. The notebook has serval sub parts, which are independent to each other, you may want to copy them to seperated python script, and run every part, to fix some memory problem.\n",
    "\n",
    "If there is any problem to reproduce, please contract me: liujilong(dot)me(at)gmail(dot)com\n",
    "\n",
    "Let's start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Embedding\n",
    "\n",
    "1. generate text file\n",
    "2. run word2vec command line. (complied from google's source code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "use_cols = ['title', 'description']\n",
    "file = '../input/fast_text.txt'\n",
    "\n",
    "\n",
    "def load_text(path, f):\n",
    "  print(f'Loading data from {path}...')\n",
    "  tic = time.time()\n",
    "  train2 = pd.read_csv(path, usecols=use_cols)\n",
    "  train2['text'] = train2['title'].astype(str) + ' ' + train2['description'].astype(str)\n",
    "  punct = string.punctuation.replace('|', '')+'\\n'\n",
    "  transtab = str.maketrans(dict.fromkeys(punct, ' '))\n",
    "\n",
    "  for text in train2['text']:\n",
    "    text = text.translate(transtab)\n",
    "    f.write(text + '\\n')\n",
    "  f.flush()\n",
    "  print('Done in {:.1f}s'.format(time.time() - tic))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  with open(file, mode='w', encoding='utf-8') as f:\n",
    "    load_text('../input/test.csv', f)\n",
    "    load_text('../input/train.csv', f)\n",
    "    load_text('../input/train_active.csv', f)\n",
    "    load_text('../input/test_active.csv', f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!word2vec -train fast_text.txt -output word2vec.bin -cbow 1 -size 200 -window 8 -negative 25 -hs 0 -sample 1e-4 -thread 12 -binary 1 -iter 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transform input from csv to pickle\n",
    "\n",
    "I do this for fast data load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/test.csv', index_col=\"item_id\",\n",
    "                       parse_dates=[\"activation_date\"])\n",
    "print(test.shape)\n",
    "test_filter = test[test['image'].notnull()]\n",
    "print(test_filter.shape)\n",
    "test_filter.to_pickle('../input/test_with_image.pickle')\n",
    "\n",
    "test = pd.read_csv('../input/test.csv', index_col=\"item_id\",\n",
    "                       parse_dates=[\"activation_date\"])\n",
    "test.to_pickle('../input/test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = ['4f029e2a00e892aa2cac27d98b52ef8b13d91471f613c8d3c38e3f29d4da0b0c', \n",
    "               '8513a91e55670c709069b5f85e12a59095b802877715903abef16b7a6f306e58', \n",
    "               '60d310a42e87cdf799afcd89dc1b11ae3fdc3d0233747ec7ef78d82c87002e83', \n",
    "               'b98b291bd04c3d92165ca515e00468fd9756af9a8f1df42505deed1dcfb5d7ae']\n",
    "\n",
    "train = pd.read_csv('../input/train.csv', index_col=\"item_id\",\n",
    "                       parse_dates=[\"activation_date\"])\n",
    "\n",
    "for img in img_id:\n",
    "    train.loc[train.image==img, 'image'] = float('nan')\n",
    "    \n",
    "train.to_pickle('../input/train.pickle')\n",
    "\n",
    "train_filter = train[train['image'].notnull()]\n",
    "\n",
    "train_filter.to_pickle('../input/train_with_image.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Meta features\n",
    "\n",
    "The code generates image meta features for train data. You should make small filepath changes to generate test iamge meta features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from math import ceil\n",
    "import cv2\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from multiprocessing import Value, Pool\n",
    "import gzip\n",
    "from pathlib import PurePath\n",
    "from scipy import sparse\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "import gc\n",
    "\n",
    "\n",
    "\n",
    "def generate_files(n_items):\n",
    "  print(\"Starting generate_files...\")\n",
    "\n",
    "  df =  pd.read_pickle('../input/train_with_image.pickle')\n",
    "  #df =  pd.read_pickle('../input/test_with_image.pickle')\n",
    "  ids = df['image'].tolist()\n",
    "  n_items.value = len(ids)\n",
    "  print(\"Total items:\", n_items.value)\n",
    "\n",
    "  for im_id in ids:\n",
    "    if im_id == 'nan' or im_id == float('nan'):\n",
    "      yield (im_id, None)\n",
    "    img_file = '../input/train_jpg/{}.jpg'.format(im_id)\n",
    "    #img_file = '../input/test_jpg/{}.jpg'.format(im_id)\n",
    "    zbuf = np.asarray(bytearray(open(img_file, 'rb').read()), dtype=\"uint8\")\n",
    "    yield (im_id, zbuf)\n",
    "\n",
    "  print(\"Finished generate_files\")\n",
    "\n",
    "def transform_image(img):\n",
    "  yuv = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "  hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "  hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "  rgb_r = img[:, :, 0]\n",
    "  rgb_g = img[:, :, 1]\n",
    "  rgb_b = img[:, :, 2]\n",
    "  yuv_y = yuv[:, :, 0]\n",
    "  hsv_s = hsv[:, :, 1]\n",
    "  hsv_v = hsv[:, :, 2]\n",
    "  hls_l = hls[:, :, 1]\n",
    "\n",
    "  res = []\n",
    "\n",
    "  # Lightness\n",
    "  res.append(np.mean(yuv_y))\n",
    "  res.append(np.std(yuv_y))\n",
    "\n",
    "  res.append(np.mean(hls_l))\n",
    "  res.append(np.std(hls_l))\n",
    "\n",
    "  # Saturation\n",
    "  res.append(np.mean(hsv_s))\n",
    "  res.append(np.std(hsv_s))\n",
    "\n",
    "  # Colorfulness\n",
    "  rgb_rg = rgb_r - rgb_g\n",
    "  rgb_yb = (rgb_r + rgb_g) / 2 - rgb_b\n",
    "  colorful = np.sqrt(np.var(rgb_rg) + np.var(rgb_yb)) + \\\n",
    "             0.3 * np.sqrt(np.mean(rgb_rg) ** 2 + np.mean(rgb_yb) ** 2)\n",
    "  res.append(colorful)\n",
    "\n",
    "  # Gray\n",
    "  res.append(np.std(gray))\n",
    "\n",
    "  # Color\n",
    "  res.append(np.mean(rgb_r))\n",
    "  res.append(np.mean(rgb_g))\n",
    "  res.append(np.mean(rgb_b))\n",
    "\n",
    "  # Shape\n",
    "  shape = img.shape\n",
    "  res.append(shape[0])\n",
    "  res.append(shape[1])\n",
    "  res.append(shape[0] * shape[1])\n",
    "\n",
    "  # Blurrness\n",
    "  res.append(cv2.Laplacian(gray, cv2.CV_64F).var())\n",
    "  return res\n",
    "\n",
    "\n",
    "def im_decode_resize(params):\n",
    "  item_id, zbuf = params\n",
    "\n",
    "  if zbuf is None:\n",
    "    return item_id, None\n",
    "  else:\n",
    "    try:\n",
    "      im = transform_image(cv2.imdecode(zbuf, cv2.IMREAD_COLOR))\n",
    "    except Exception as e:\n",
    "      print('Error decoding item_id', item_id, e)\n",
    "      im = [0] * 15\n",
    "\n",
    "    return item_id, im\n",
    "\n",
    "\n",
    "# Based on https://gist.github.com/everilae/9697228\n",
    "class ThreadedGenerator(object):\n",
    "  \"\"\"\n",
    "  Generator that runs on a separate thread, returning values to calling\n",
    "  thread. Care must be taken that the iterator does not mutate any shared\n",
    "  variables referenced in the calling thread.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, iterator, queue_maxsize):\n",
    "    self._iterator = iterator\n",
    "    self._sentinel = object()\n",
    "    self._queue = Queue(maxsize=queue_maxsize)\n",
    "    self._thread = Thread(\n",
    "      name=repr(iterator),\n",
    "      target=self._run\n",
    "    )\n",
    "\n",
    "  def __repr__(self):\n",
    "    return 'ThreadedGenerator({!r})'.format(self._iterator)\n",
    "\n",
    "  def _run(self):\n",
    "    try:\n",
    "      for value in self._iterator:\n",
    "        self._queue.put(value)\n",
    "\n",
    "    finally:\n",
    "      self._queue.put(self._sentinel)\n",
    "\n",
    "  def __iter__(self):\n",
    "    self._thread.start()\n",
    "    for value in iter(self._queue.get, self._sentinel):\n",
    "      yield value\n",
    "\n",
    "    self._thread.join()\n",
    "\n",
    "\n",
    "def get_shape(input, length):\n",
    "  shape = getattr(input, \"shape\", None)\n",
    "  if shape == None:\n",
    "    shape = (len(input),)\n",
    "  return (length,) + shape\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  print(\"Loading model...\")\n",
    "\n",
    "  n_items = Value('i', -1)  # Async number of items\n",
    "  pool = Pool(5)\n",
    "  final = None\n",
    "  bar = None\n",
    "  try:\n",
    "    start = time.time()\n",
    "    count = 0\n",
    "    generator = ThreadedGenerator(generate_files(n_items), 50)\n",
    "    for index, (item_id, im) in enumerate(pool.imap(im_decode_resize, generator)):\n",
    "      if bar is None:\n",
    "        bar = tqdm(total=n_items.value, mininterval=10, unit_scale=True)\n",
    "      if final is None:\n",
    "        final = np.zeros(shape=get_shape(im, n_items.value))\n",
    "      final[index] = im\n",
    "      count += 1\n",
    "      batch_size = 1000\n",
    "      if count % batch_size == 0:\n",
    "        bar.update(batch_size)\n",
    "\n",
    "\n",
    "  finally:\n",
    "    pool.close()\n",
    "    del pool, bar\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "  np.save('../input/train_image_meta_wihtout_zero_size.npy', final)\n",
    "  #np.save('../input/test_image_meta.npy', final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image score features\n",
    "ImageNet score and NIMA score for images. Also only for train, do some filepath changes for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from math import ceil\n",
    "import cv2\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "from keras.preprocessing import image\n",
    "import keras.applications.resnet50 as resnet50\n",
    "import keras.applications.xception as xception\n",
    "import keras.applications.inception_v3 as inception_v3\n",
    "from multiprocessing import Value, Pool, Semaphore\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout\n",
    "import gzip\n",
    "from pathlib import PurePath\n",
    "from scipy import sparse\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "import gc\n",
    "\n",
    "\n",
    "def generate_files(n_items):\n",
    "  print(\"Starting generate_files...\")\n",
    "\n",
    "  df = pd.read_pickle('../input/train_with_image.pickle')\n",
    "  # df = df.iloc[:200]\n",
    "  ids = df['image'].tolist()\n",
    "  n_items.value = len(ids)\n",
    "  print(\"Total items:\", n_items.value)\n",
    "\n",
    "  for im_id in ids:\n",
    "    yield im_id\n",
    "  print(\"Finished generate_files\")\n",
    "\n",
    "\n",
    "def decode_resize(im_id):\n",
    "  img_file = '../../JPG_Avito/train_jpg/{}.jpg'.format(im_id)\n",
    "  semaphore_1.acquire()\n",
    "  img = cv2.imread(img_file)\n",
    "  # if img is None:\n",
    "  #   img = np.zeros(shape=(224, 224, 3))\n",
    "  target_size = (224, 224)\n",
    "  if img.size != target_size:\n",
    "    img = cv2.resize(img, target_size, interpolation=cv2.INTER_CUBIC)\n",
    "  return im_id, img\n",
    "\n",
    "\n",
    "# Based on https://gist.github.com/everilae/9697228\n",
    "class ThreadedGenerator(object):\n",
    "  \"\"\"\n",
    "  Generator that runs on a separate thread, returning values to calling\n",
    "  thread. Care must be taken that the iterator does not mutate any shared\n",
    "  variables referenced in the calling thread.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, iterator, queue_maxsize):\n",
    "    self._iterator = iterator\n",
    "    self._sentinel = object()\n",
    "    self._queue = Queue(maxsize=queue_maxsize)\n",
    "    self._thread = Thread(\n",
    "      name=repr(iterator),\n",
    "      target=self._run\n",
    "    )\n",
    "\n",
    "  def __repr__(self):\n",
    "    return 'ThreadedGenerator({!r})'.format(self._iterator)\n",
    "\n",
    "  def _run(self):\n",
    "    try:\n",
    "      for value in self._iterator:\n",
    "        self._queue.put(value)\n",
    "\n",
    "    finally:\n",
    "      self._queue.put(self._sentinel)\n",
    "\n",
    "  def __iter__(self):\n",
    "    self._thread.start()\n",
    "    for value in iter(self._queue.get, self._sentinel):\n",
    "      yield value\n",
    "\n",
    "    self._thread.join()\n",
    "\n",
    "\n",
    "def get_shape(input, length):\n",
    "  shape = getattr(input, \"shape\", None)\n",
    "  if shape is None:\n",
    "    shape = (len(input),)\n",
    "  return (length,) + shape\n",
    "\n",
    "def get_nima_model():\n",
    "  base_model = InceptionResNetV2(input_shape=(None, None, 3), include_top=False,\n",
    "                                 pooling='avg', weights=None)\n",
    "  x = Dropout(0.75)(base_model.output)\n",
    "  x = Dense(10, activation='softmax')(x)\n",
    "\n",
    "  model = Model(base_model.input, x)\n",
    "  model.load_weights('../input/inception_resnet_weights.h5')\n",
    "  return model\n",
    "\n",
    "\n",
    "resnet_model = resnet50.ResNet50(weights='imagenet')\n",
    "inception_model = inception_v3.InceptionV3(weights='imagenet')\n",
    "xception_model = xception.Xception(weights='imagenet')\n",
    "vgg16 = VGG16(weights='imagenet')\n",
    "nima_model = get_nima_model()\n",
    "\n",
    "\n",
    "def mean_score(scores):\n",
    "    si = np.arange(1, 11, 1)\n",
    "    mean = np.sum(scores * si, axis=1)\n",
    "    return mean\n",
    "\n",
    "\n",
    "def predict_batch(ori_batch):\n",
    "\n",
    "  caffee_batch = resnet50.preprocess_input(np.array(ori_batch, dtype=np.float32))\n",
    "  tf_batch = inception_v3.preprocess_input(np.array(ori_batch, dtype=np.float32))\n",
    "  vgg_fea = vgg16.predict_on_batch(caffee_batch)\n",
    "  resnet_fea = resnet_model.predict_on_batch(caffee_batch)\n",
    "  incep_fea = inception_model.predict_on_batch(tf_batch)\n",
    "  xcep_fea = xception_model.predict_on_batch(tf_batch)\n",
    "\n",
    "  nima_fea = nima_model.predict_on_batch(tf_batch)\n",
    "  mean = mean_score(nima_fea)\n",
    "\n",
    "\n",
    "  res = np.max(vgg_fea, axis=1), np.max(resnet_fea, axis=1), np.max(incep_fea, axis=1), np.max(xcep_fea, axis=1), mean\n",
    "  return np.stack(res, axis=1)\n",
    "\n",
    "batch_size = 128\n",
    "bar_iterval = 10  # in seconds\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  print(\"Loading model...\")\n",
    "\n",
    "  semaphore_1 = Semaphore(2048)\n",
    "  n_items = Value('i', -1)  # Async number of items\n",
    "  pool = Pool(2)\n",
    "  bar = None\n",
    "  X_batch = []\n",
    "  result = None\n",
    "  total_size = 0\n",
    "  try:\n",
    "    # Threaded generator is usful for both parallel blocking read and to limit\n",
    "    # items buffered by pool.imap (may cause OOM)\n",
    "    generator = ThreadedGenerator(generate_files(n_items), 50)\n",
    "    for item_id, im in pool.imap(decode_resize, generator):\n",
    "      if bar is None:\n",
    "        bar = tqdm(total=n_items.value, mininterval=bar_iterval,\n",
    "                   unit_scale=True)\n",
    "\n",
    "      X_batch.append(im)\n",
    "      del im\n",
    "      semaphore_1.release()\n",
    "\n",
    "      if len(X_batch) == batch_size:\n",
    "        batch_res = predict_batch(X_batch)\n",
    "        if result is None:\n",
    "          result = np.zeros(shape=get_shape(batch_res[0], n_items.value))\n",
    "        result[total_size:total_size+batch_size] = batch_res\n",
    "        total_size += batch_size\n",
    "        del X_batch\n",
    "        X_batch = []\n",
    "        bar.update(batch_size)\n",
    "\n",
    "    if len(X_batch) > 0:\n",
    "        batch_res = predict_batch(X_batch)\n",
    "        result[total_size:n_items.value] = batch_res\n",
    "    bar.update(len(X_batch))\n",
    "\n",
    "  finally:\n",
    "    pool.close()\n",
    "    del pool, X_batch\n",
    "\n",
    "    if bar:\n",
    "      bar.close()\n",
    "\n",
    "    gc.collect()\n",
    "    print(result.shape)\n",
    "    np.save('../input/train_img_score.npy', result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image numpy file\n",
    "\n",
    "preprocess image files to one total numpy file, for fast load.\n",
    "\n",
    "same for train-test file path change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sys import getsizeof\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "df = pd.read_csv('../input/train.csv', index_col=\"item_id\",\n",
    "                         parse_dates=[\"activation_date\"])\n",
    "img = df['image']\n",
    "total_img = np.zeros(shape=(df.shape[0], 80, 60, 3), dtype=np.uint8)\n",
    "\n",
    "for index, img_id in tqdm(enumerate(img)):\n",
    "    img_file = '../input/train_jpg/{}.jpg'.format(img[index])\n",
    "    iii = cv2.imread(img_file)\n",
    "    if iii is not None:\n",
    "        iii2 = cv2.resize(iii, (60, 80), interpolation=cv2.INTER_CUBIC)\n",
    "        total_img[index] = iii2\n",
    "        \n",
    "np.save('train_img.npy', total_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
